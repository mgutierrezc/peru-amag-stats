{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "96f1d9a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json, os, string\n",
    "from janitor import clean_names\n",
    "from fuzzywuzzy import fuzz\n",
    "from fuzzywuzzy import process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "c6ac7f74",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def read_json_dict(path: str) -> dict:\n",
    "    \"\"\"\n",
    "    Reads a json file and returns it as dict object\n",
    "    \"\"\"\n",
    "    \n",
    "    file = open(path) # Opening JSON file\n",
    "    return json.load(file) # returns JSON object as a dictionary\n",
    "\n",
    "def folder_creator(folder_name: string, path: string) -> None:\n",
    "    \"\"\"\n",
    "    Generates a folder in specified path\n",
    "    \n",
    "    input: name of root folder, path where you want \n",
    "    folder to be created\n",
    "    output: None\n",
    "    \"\"\"\n",
    "    \n",
    "    # defining paths\n",
    "    data_folder_path = path + \"/\" + folder_name\n",
    "    data_folder_exists = os.path.exists(data_folder_path)\n",
    "\n",
    "    # creating folders if don't exist\n",
    "    if data_folder_exists:\n",
    "        pass\n",
    "    else:    \n",
    "        # create a new directory because it does not exist \n",
    "        os.makedirs(data_folder_path)\n",
    "\n",
    "        # create subfolders\n",
    "        print(f\"The new directory {folder_name} was created!\")\n",
    "        \n",
    "def fuzzy_merge(df_1, df_2, key1, key2, threshold=90, limit=2):\n",
    "    \"\"\"\n",
    "    :param df_1: the left table to join\n",
    "    :param df_2: the right table to join\n",
    "    :param key1: key column of the left table\n",
    "    :param key2: key column of the right table\n",
    "    :param threshold: how close the matches should be to return a match, based on Levenshtein distance\n",
    "    :param limit: the amount of matches that will get returned, these are sorted high to low\n",
    "    :return: dataframe with boths keys and matches\n",
    "    \"\"\"\n",
    "    s = df_2[key2].tolist()\n",
    "    \n",
    "    m = df_1[key1].apply(lambda x: process.extract(x, s, limit=limit))    \n",
    "    df_1['matches'] = m\n",
    "    \n",
    "    m2 = df_1['matches'].apply(lambda x: ', '.join([i[0] for i in x if i[1] >= threshold]))\n",
    "    df_1['matches'] = m2\n",
    "    \n",
    "    return df_1\n",
    "\n",
    "def create_pickle(object_name, file_name: str, path: str) -> None:\n",
    "    \"\"\"\n",
    "    Creates a pickle file for object. Note: Path should have no slash \n",
    "    at the end\n",
    "    \"\"\"\n",
    "    with open(path + f\"/{file_name}\", \"wb\") as storing_output:\n",
    "        pickle.dump(object_name, storing_output)\n",
    "        storing_output.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4112dfa4",
   "metadata": {},
   "source": [
    "## Reading paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6c5e9630",
   "metadata": {},
   "outputs": [],
   "source": [
    "paths = read_json_dict(\"paths.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0ac272d4",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'data_path': 'D:/Accesos directos/Trabajo/World Bank/WB Repos/peru-scrape-justice',\n",
       " 'code_path': '/Users/brandonmora/GitHub/peru-amag-stats/case_outcomes',\n",
       " 'data_amag_i': 'D:/Accesos directos/Trabajo/World Bank/WB Repos/peru-scrape-justice/01_AMAG',\n",
       " 'data_cej': 'D:/Accesos directos/Trabajo/World Bank/WB Repos/peru-scrape-justice/data_cleaned_',\n",
       " 'data_gender': 'D:/Accesos directos/Trabajo/World Bank/WB Repos/peru-scrape-justice/07_Other/02_Raw/names_gender',\n",
       " 'local_storage': 'D:/Daniel Chen Dropbox/Marco Antonio GutiÃ©rrez ChÃ¡vez/datasets_amag_ii_scrape'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "66e888ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = paths[\"data_path\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0ac86717",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_creator(\"data_cleaned\", data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "427a39da",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_cleaned_path = data_path + \"/data_cleaned\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "35c9e95a",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_creator(\"raw\", data_cleaned_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "18c389b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "dc_raw_path = data_cleaned_path + \"/raw\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "28455124",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The new directory temp was created!\n"
     ]
    }
   ],
   "source": [
    "folder_creator(\"temp\", data_cleaned_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "f92a94a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "dc_temp_path = data_cleaned_path + \"/temp\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "475624d8",
   "metadata": {},
   "source": [
    "# 1. Creating participants list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdb9b754",
   "metadata": {},
   "source": [
    "Reading lab data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0123568b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lab_data = pd.read_stata(data_path + \"/data/lab_Data/Clean_Full_Data12.dta\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7054f37",
   "metadata": {},
   "source": [
    "Creating name variables for future fuzzy merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8a5db534",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Gigabyte\\AppData\\Local\\Temp\\ipykernel_68832\\4041196165.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lab_data[\"participant_nombre_apellido\"] = lab_data[\"Nombres\"] + \" \" + lab_data[\"ApellidoPaterno\"] + \" \" + lab_data[\"ApellidoMaterno\"]\n"
     ]
    }
   ],
   "source": [
    "lab_data[\"participant_nombre_apellido\"] = lab_data[\"Nombres\"] + \" \" + lab_data[\"ApellidoPaterno\"] + \" \" + lab_data[\"ApellidoMaterno\"]\n",
    "lab_data[\"participant_nombre_apellido\"] = lab_data[\"participant_nombre_apellido\"].str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f63ca845",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Gigabyte\\AppData\\Local\\Temp\\ipykernel_68832\\909368064.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lab_data[\"participant_apellido_nombre\"] = lab_data[\"ApellidoPaterno\"] + \" \" + lab_data[\"ApellidoMaterno\"] + \" \" + lab_data[\"Nombres\"]\n"
     ]
    }
   ],
   "source": [
    "lab_data[\"participant_apellido_nombre\"] = lab_data[\"ApellidoPaterno\"] + \" \" + lab_data[\"ApellidoMaterno\"] + \" \" + lab_data[\"Nombres\"]\n",
    "lab_data[\"participant_apellido_nombre\"] = lab_data[\"participant_apellido_nombre\"].str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5a1a4b26",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lab_data = lab_data.rename(columns={\"DNI\": \"nrodocumento\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7872d1a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "amag_ii_participants = lab_data[[\"nrodocumento\", \"participant_nombre_apellido\", \"participant_apellido_nombre\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf7a4d84",
   "metadata": {},
   "source": [
    "Exporting the list of participants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1cb27e50",
   "metadata": {},
   "outputs": [],
   "source": [
    "amag_ii_participants.to_csv(dc_raw_path + \"/amag_ii_participants_list.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8210558",
   "metadata": {},
   "source": [
    "# 2. Creating Cases List"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e655645",
   "metadata": {},
   "source": [
    "### 2.0. Selecting reporte files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "81d05649",
   "metadata": {},
   "outputs": [],
   "source": [
    "files_reports = pd.read_csv(dc_raw_path + \"/DF_file_report_2022.csv\")\n",
    "files_reports = clean_names(files_reports)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91cc3474",
   "metadata": {},
   "source": [
    "### 2.1. Cleaning the reporte files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5392bfa",
   "metadata": {},
   "source": [
    "Creating lists with characters to be replace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d6b9e0e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "backslash_reps = [\"\\\\(\\\\*\\\\)\", \"\\\\\", \"\\\\([^()]{0,}\\\\)\"]\n",
    "trailing_and_special_reps = [\"^\\\\s\", \"\\\\,\", \"\\\\.$\", \" \\\\- JUZ$\", \"\\\\*\"]\n",
    "other_strs_reps = [\"\\\\- MIXTO Y LIQ\", \"\\\\- MIXTO\", \"\\\\- JUZ\\\\. MIXTO\", \n",
    "                   \"- JM\", \"- INVESTIGACION\", \"- PAZ LETRADO\", \"SECOM - \", \"- JT\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84d190e2",
   "metadata": {},
   "source": [
    "### 2.2. Replacing backlashes, special characters and other uninformative characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "110c4060",
   "metadata": {},
   "outputs": [],
   "source": [
    "empty_reps = backslash_reps + trailing_and_special_reps +  other_strs_reps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c1131709",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Gigabyte\\AppData\\Local\\Temp\\ipykernel_68832\\3422139958.py:2: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  files_reports[\"juez_\"] = files_reports[\"juez_\"].str.replace(val, \"\")\n",
      "C:\\Users\\Gigabyte\\AppData\\Local\\Temp\\ipykernel_68832\\3422139958.py:2: FutureWarning: The default value of regex will change from True to False in a future version. In addition, single character regular expressions will *not* be treated as literal strings when regex=True.\n",
      "  files_reports[\"juez_\"] = files_reports[\"juez_\"].str.replace(val, \"\")\n"
     ]
    }
   ],
   "source": [
    "for val in empty_reps:    \n",
    "    files_reports[\"juez_\"] = files_reports[\"juez_\"].str.replace(val, \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d228a4d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "name_reps = [[\"ALFREDO E\\\\.\", \"ALFREDO E\"], [\"BERTHA F\\\\.\", \"BERTHA F\"], [\"CLAUDIO W\\\\.\", \"CLAUDIO W\"], \n",
    "            [\"CLAVELITO L\\\\.\", \"CLAVELITO L\"], [\"ELMER L\\\\.\", \"ELMER L\"], [\"ERNESTO A\\\\.\", \"ERNESTO A\"],\n",
    "            [\"HERBERT M\\\\.\", \"HERBERT M\"], [\"LUZ K\\\\.\", \"LUZ K\"], [\"NANCY S\\\\.\", \"NANCY S\"], [\"JESSICA E\\\\.\", \"JESSICA E\"],\n",
    "            [\"PATRICIA C\\\\.\", \"PATRICIA C\"], [\"JESSICA P\\\\.\", \"JESSICA P\"], [\"YOLANDA B\\\\.\", \"YOLANDA B\\\\.\"],\n",
    "            [\"LUZ M\\\\.\", \"LUZ M\"], [\"EDGAR\\\\.\", \"EDGAR\"], [\"C\\\\. ARTURO\", \"C ARTURO\"], [\"ALEXANDER A\\\\.\", \"ALEXANDER A\"],\n",
    "            [\"RENE G\\\\.\", \"RENE G\"], [\"GUILLERMO S\\\\.\", \"GUILLERMO S\"], [\"FANNY L\\\\. \",  \"FANNY L\"], [\"ELISA \\\\(LA\", \"ELISA\"],\n",
    "            [\"JULIA \\\\(LA\", \"JULIA\"], [\"ACEVEDO DIEZ CECILIA\", \"ACEVEDO DIEZ CECILIA DEL PILAR\"], [\" J. \", \" J \"],\n",
    "            [\" K. \", \" K \"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1efd115c",
   "metadata": {},
   "source": [
    "### 2.3. Replacing names with issues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "77f62c47",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Gigabyte\\AppData\\Local\\Temp\\ipykernel_68832\\4277728364.py:2: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  files_reports[\"juez_\"] = files_reports[\"juez_\"].str.replace(name_rep[0], name_rep[1])\n"
     ]
    }
   ],
   "source": [
    "for name_rep in name_reps:\n",
    "    files_reports[\"juez_\"] = files_reports[\"juez_\"].str.replace(name_rep[0], name_rep[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83eff7bc",
   "metadata": {},
   "source": [
    "### 2.4. Obtaining the names of judges"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cef956de",
   "metadata": {},
   "source": [
    "Some cases have multiple judges assigned to them. As a result, we need to extract these names as we will match the case with the judge information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f57f87f7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "files_reports = files_reports[files_reports[\"juez_\"].notna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7fdbf7b0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "files_reports[\"juez_splitted\"] = files_reports[\"juez_\"].apply(lambda row: row.split(\".\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "12f99917",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "files_reports[\"n_judges_case\"] = files_reports[\"juez_splitted\"].apply(lambda row: len(row))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1e1de66b",
   "metadata": {},
   "outputs": [],
   "source": [
    "judge_names = files_reports[files_reports[\"n_judges_case\"] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "366e60bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "multiple_judge_names = files_reports[files_reports[\"n_judges_case\"] != 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0f6cb645",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Gigabyte\\AppData\\Local\\Temp\\ipykernel_68832\\160945290.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  multiple_judge_names[\"juez_1\"] = multiple_judge_names[\"juez_splitted\"].apply(lambda row: row[0])\n",
      "C:\\Users\\Gigabyte\\AppData\\Local\\Temp\\ipykernel_68832\\160945290.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  multiple_judge_names[\"juez_2\"] = multiple_judge_names[\"juez_splitted\"].apply(lambda row: row[1])\n",
      "C:\\Users\\Gigabyte\\AppData\\Local\\Temp\\ipykernel_68832\\160945290.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  multiple_judge_names[\"juez_3\"] = multiple_judge_names[\"juez_splitted\"].apply(lambda row: row[2])\n"
     ]
    }
   ],
   "source": [
    "multiple_judge_names[\"juez_1\"] = multiple_judge_names[\"juez_splitted\"].apply(lambda row: row[0])\n",
    "multiple_judge_names[\"juez_2\"] = multiple_judge_names[\"juez_splitted\"].apply(lambda row: row[1])\n",
    "multiple_judge_names[\"juez_3\"] = multiple_judge_names[\"juez_splitted\"].apply(lambda row: row[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "63556233",
   "metadata": {},
   "outputs": [],
   "source": [
    "judge_names = judge_names.rename(columns={\"juez_\": \"juez\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b2946eb",
   "metadata": {},
   "source": [
    "### 2.5. Fuzzy merge with Lab Experiment Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0da6153",
   "metadata": {},
   "source": [
    "Creating debuggings dataset to simulate the fuzzy merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "aa24dba5",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['expediente_n°_', 'organo_jurisdiccional_', 'distrito_judicial_',\n",
       "       'juez', 'especialista_legal_', 'fecha_de_inicio_', 'proceso_',\n",
       "       'observacion_', 'especialidad_', 'materia_s_', 'estado_',\n",
       "       'etapa_procesal_', 'fecha_conclusion_', 'ubicacion_',\n",
       "       'motivo_conclusion_', 'sumilla_', 'juez_splitted', 'n_judges_case'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "judge_names.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "583329db",
   "metadata": {},
   "outputs": [],
   "source": [
    "debug_judges = judge_names[(judge_names[\"juez\"] == \"CRUZADO MEJIA MARTIN VALDEMAR\") |\n",
    "                           (judge_names[\"juez\"] == \"APAGUEÑO REATEGUI BRYAN ENRIQUE\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "ce48016a",
   "metadata": {},
   "outputs": [],
   "source": [
    "debug_participants = amag_ii_participants[(amag_ii_participants[\"participant_apellido_nombre\"] == \"CRUZADO MEJIA MARTIN VALDEMAR\") |\n",
    "                                          (amag_ii_participants[\"participant_apellido_nombre\"] == \"APAGUEÑO REATEGUI BRYAN ENRIQUE\")]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "337cd274",
   "metadata": {},
   "source": [
    "Fuzzy match of cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "c1d59bd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Gigabyte\\AppData\\Local\\Temp\\ipykernel_68832\\3876909639.py:45: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_1['matches'] = m\n",
      "C:\\Users\\Gigabyte\\AppData\\Local\\Temp\\ipykernel_68832\\3876909639.py:48: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_1['matches'] = m2\n"
     ]
    }
   ],
   "source": [
    "matched_judge_name1 = fuzzy_merge(debug_judges, debug_participants, \"juez\", \"participant_apellido_nombre\", threshold=90, limit=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "e684782a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "amag_ii_cases = matched_judge_name1.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4123ca72",
   "metadata": {},
   "source": [
    "# 3. Creating CEJ datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df641710",
   "metadata": {},
   "source": [
    "A pending task would be to bind the rows of all the dataframes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5789879",
   "metadata": {},
   "source": [
    "## Follow up dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a9d607d9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Gigabyte\\AppData\\Local\\Temp\\ipykernel_68832\\994655769.py:1: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version. Use on_bad_lines in the future.\n",
      "\n",
      "\n",
      "  files_follow_up = pd.read_csv(dc_raw_path + \"/DF_follow_up_cleaner_2022.csv\", error_bad_lines=False)\n",
      "Skipping line 8128: expected 10 fields, saw 11\n",
      "\n"
     ]
    }
   ],
   "source": [
    "files_follow_up = pd.read_csv(dc_raw_path + \"/DF_follow_up_cleaner_2022.csv\", error_bad_lines=False)\n",
    "files_follow_up = clean_names(files_follow_up)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0478cbf0",
   "metadata": {},
   "source": [
    "# Procedural parts dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "1ce34c6a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "files_procedural_parts = pd.read_csv(dc_raw_path + \"/DF_procedural_parts_2022.csv\")\n",
    "files_procedural_parts = clean_names(files_procedural_parts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "b771db6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "files_procedural_parts[\"expediente_n°_\"] = files_procedural_parts[\"expediente_n°_\"].apply(lambda row: row.split(\"\\\\\")[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c82d5d16",
   "metadata": {},
   "source": [
    "## Downloads dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "1dfaaf54",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "files_downloads = pd.read_csv(dc_raw_path + \"/DF_DOWNLOADS_2022.csv\")\n",
    "files_downloads = clean_names(files_downloads)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4e52311",
   "metadata": {},
   "source": [
    "### Merging complementary case data with amag ii cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "7f539372",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "amag_ii_cases = pd.merge(amag_ii_cases, files_reports, how=\"inner\", on=\"expediente_n°_\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "c55ce800",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "amag_ii_cases = pd.merge(amag_ii_cases, files_follow_up, how=\"inner\", on=\"expediente_n°_\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "9b9fd27b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "amag_ii_cases = pd.merge(amag_ii_cases, files_procedural_parts, how=\"inner\", on=\"expediente_n°_\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "70853079",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "amag_ii_cases = pd.merge(amag_ii_cases, files_downloads, how=\"inner\", left_on=\"expediente_n°_\", right_on=\"expediente_num\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "480d8189",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function create_pickle in module __main__:\n",
      "\n",
      "create_pickle(object_name, file_name: str, path: str) -> None\n",
      "    Creates a pickle file for object. Note: Path should have no slash \n",
      "    at the end\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(create_pickle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "c570d71b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "create_pickle(amag_ii_cases, \"amag_ii_cases.pkl\", dc_temp_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Judges Outcomes",
   "language": "python",
   "name": "judges_outcomes"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
