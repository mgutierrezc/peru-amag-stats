{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "96f1d9a2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import regex as re\n",
    "import nltk\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json, os, string\n",
    "from janitor import clean_names\n",
    "from fuzzywuzzy import fuzz\n",
    "from fuzzywuzzy import process\n",
    "from datetime import datetime\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "c6ac7f74",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def read_json_dict(path: str) -> dict:\n",
    "    \"\"\"\n",
    "    Reads a json file and returns it as dict object\n",
    "    \"\"\"\n",
    "    \n",
    "    file = open(path) # Opening JSON file\n",
    "    return json.load(file) # returns JSON object as a dictionary\n",
    "\n",
    "def folder_creator(folder_name: string, path: string) -> None:\n",
    "    \"\"\"\n",
    "    Generates a folder in specified path\n",
    "    \n",
    "    input: name of root folder, path where you want \n",
    "    folder to be created\n",
    "    output: None\n",
    "    \"\"\"\n",
    "    \n",
    "    # defining paths\n",
    "    data_folder_path = path + \"/\" + folder_name\n",
    "    data_folder_exists = os.path.exists(data_folder_path)\n",
    "\n",
    "    # creating folders if don't exist\n",
    "    if data_folder_exists:\n",
    "        pass\n",
    "    else:    \n",
    "        # create a new directory because it does not exist \n",
    "        os.makedirs(data_folder_path)\n",
    "\n",
    "        # create subfolders\n",
    "        print(f\"The new directory {folder_name} was created!\")\n",
    "        \n",
    "def fuzzy_merge(df_1, df_2, key1, key2, threshold=90, limit=2):\n",
    "    \"\"\"\n",
    "    :param df_1: the left table to join\n",
    "    :param df_2: the right table to join\n",
    "    :param key1: key column of the left table\n",
    "    :param key2: key column of the right table\n",
    "    :param threshold: how close the matches should be to return a match, based on Levenshtein distance\n",
    "    :param limit: the amount of matches that will get returned, these are sorted high to low\n",
    "    :return: dataframe with boths keys and matches\n",
    "    \"\"\"\n",
    "    s = df_2[key2].tolist()\n",
    "    \n",
    "    m = df_1[key1].apply(lambda x: process.extract(x, s, limit=limit))    \n",
    "    df_1['matches'] = m\n",
    "    \n",
    "    m2 = df_1['matches'].apply(lambda x: ', '.join([i[0] for i in x if i[1] >= threshold]))\n",
    "    df_1['matches'] = m2\n",
    "    \n",
    "    return df_1\n",
    "\n",
    "def create_pickle(object_name, file_name: str, path: str) -> None:\n",
    "    \"\"\"\n",
    "    Creates a pickle file for object. Note: Path should have no slash \n",
    "    at the end\n",
    "    \"\"\"\n",
    "    with open(path + f\"/{file_name}\", \"wb\") as storing_output:\n",
    "        pickle.dump(object_name, storing_output)\n",
    "        storing_output.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4112dfa4",
   "metadata": {},
   "source": [
    "## Reading paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6c5e9630",
   "metadata": {},
   "outputs": [],
   "source": [
    "paths = read_json_dict(\"paths.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0ac272d4",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'data_path': 'D:/Accesos directos/Trabajo/World Bank/WB Repos/peru-scrape-justice',\n",
       " 'code_path': '/Users/brandonmora/GitHub/peru-amag-stats/case_outcomes',\n",
       " 'data_amag_i': 'D:/Accesos directos/Trabajo/World Bank/WB Repos/peru-scrape-justice/01_AMAG',\n",
       " 'data_cej': 'D:/Accesos directos/Trabajo/World Bank/WB Repos/peru-scrape-justice/data_cleaned_',\n",
       " 'data_gender': 'D:/Accesos directos/Trabajo/World Bank/WB Repos/peru-scrape-justice/07_Other/02_Raw/names_gender',\n",
       " 'local_storage': 'D:/Daniel Chen Dropbox/Marco Antonio GutiÃ©rrez ChÃ¡vez/datasets_amag_ii_scrape'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "66e888ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = paths[\"data_path\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0ac86717",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_creator(\"data_cleaned\", data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "427a39da",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_cleaned_path = data_path + \"/data_cleaned\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "35c9e95a",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_creator(\"raw\", data_cleaned_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "18c389b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "dc_raw_path = data_cleaned_path + \"/raw\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "9dd0193b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The new directory temp was created!\n"
     ]
    }
   ],
   "source": [
    "folder_creator(\"temp\", data_cleaned_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "daa52ceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "dc_temp_path = data_cleaned_path + \"/temp\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "475624d8",
   "metadata": {},
   "source": [
    "# 1. Creating participants list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "702d6ee6",
   "metadata": {},
   "source": [
    "Reading lab data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0123568b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lab_data = pd.read_stata(data_path + \"/data/lab_Data/Clean_Full_Data12.dta\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7861e8a3",
   "metadata": {},
   "source": [
    "Creating name variables for future fuzzy merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8a5db534",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Gigabyte\\AppData\\Local\\Temp\\ipykernel_68832\\4041196165.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lab_data[\"participant_nombre_apellido\"] = lab_data[\"Nombres\"] + \" \" + lab_data[\"ApellidoPaterno\"] + \" \" + lab_data[\"ApellidoMaterno\"]\n"
     ]
    }
   ],
   "source": [
    "lab_data[\"participant_nombre_apellido\"] = lab_data[\"Nombres\"] + \" \" + lab_data[\"ApellidoPaterno\"] + \" \" + lab_data[\"ApellidoMaterno\"]\n",
    "lab_data[\"participant_nombre_apellido\"] = lab_data[\"participant_nombre_apellido\"].str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f63ca845",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Gigabyte\\AppData\\Local\\Temp\\ipykernel_68832\\909368064.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  lab_data[\"participant_apellido_nombre\"] = lab_data[\"ApellidoPaterno\"] + \" \" + lab_data[\"ApellidoMaterno\"] + \" \" + lab_data[\"Nombres\"]\n"
     ]
    }
   ],
   "source": [
    "lab_data[\"participant_apellido_nombre\"] = lab_data[\"ApellidoPaterno\"] + \" \" + lab_data[\"ApellidoMaterno\"] + \" \" + lab_data[\"Nombres\"]\n",
    "lab_data[\"participant_apellido_nombre\"] = lab_data[\"participant_apellido_nombre\"].str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5a1a4b26",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lab_data = lab_data.rename(columns={\"DNI\": \"nrodocumento\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7872d1a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "amag_ii_participants = lab_data[[\"nrodocumento\", \"participant_nombre_apellido\", \"participant_apellido_nombre\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55df507c",
   "metadata": {},
   "source": [
    "Exporting the list of participants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1cb27e50",
   "metadata": {},
   "outputs": [],
   "source": [
    "amag_ii_participants.to_csv(dc_raw_path + \"/amag_ii_participants_list.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8210558",
   "metadata": {},
   "source": [
    "# 2. Creating Cases List"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e655645",
   "metadata": {},
   "source": [
    "### 2.0. Selecting reporte files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "81d05649",
   "metadata": {},
   "outputs": [],
   "source": [
    "files_reports = pd.read_csv(dc_raw_path + \"/DF_file_report_2022.csv\")\n",
    "files_reports = clean_names(files_reports)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91cc3474",
   "metadata": {},
   "source": [
    "### 2.1. Cleaning the reporte files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5392bfa",
   "metadata": {},
   "source": [
    "Creating lists with characters to be replace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d6b9e0e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "backslash_reps = [\"\\\\(\\\\*\\\\)\", \"\\\\\", \"\\\\([^()]{0,}\\\\)\"]\n",
    "trailing_and_special_reps = [\"^\\\\s\", \"\\\\,\", \"\\\\.$\", \" \\\\- JUZ$\", \"\\\\*\"]\n",
    "other_strs_reps = [\"\\\\- MIXTO Y LIQ\", \"\\\\- MIXTO\", \"\\\\- JUZ\\\\. MIXTO\", \n",
    "                   \"- JM\", \"- INVESTIGACION\", \"- PAZ LETRADO\", \"SECOM - \", \"- JT\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7824dea",
   "metadata": {},
   "source": [
    "### 2.2. Replacing backlashes, special characters and other uninformative characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "110c4060",
   "metadata": {},
   "outputs": [],
   "source": [
    "empty_reps = backslash_reps + trailing_and_special_reps +  other_strs_reps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c1131709",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Gigabyte\\AppData\\Local\\Temp\\ipykernel_68832\\3422139958.py:2: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  files_reports[\"juez_\"] = files_reports[\"juez_\"].str.replace(val, \"\")\n",
      "C:\\Users\\Gigabyte\\AppData\\Local\\Temp\\ipykernel_68832\\3422139958.py:2: FutureWarning: The default value of regex will change from True to False in a future version. In addition, single character regular expressions will *not* be treated as literal strings when regex=True.\n",
      "  files_reports[\"juez_\"] = files_reports[\"juez_\"].str.replace(val, \"\")\n"
     ]
    }
   ],
   "source": [
    "for val in empty_reps:    \n",
    "    files_reports[\"juez_\"] = files_reports[\"juez_\"].str.replace(val, \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "809d5282",
   "metadata": {},
   "outputs": [],
   "source": [
    "name_reps = [[\"ALFREDO E\\\\.\", \"ALFREDO E\"], [\"BERTHA F\\\\.\", \"BERTHA F\"], [\"CLAUDIO W\\\\.\", \"CLAUDIO W\"], \n",
    "            [\"CLAVELITO L\\\\.\", \"CLAVELITO L\"], [\"ELMER L\\\\.\", \"ELMER L\"], [\"ERNESTO A\\\\.\", \"ERNESTO A\"],\n",
    "            [\"HERBERT M\\\\.\", \"HERBERT M\"], [\"LUZ K\\\\.\", \"LUZ K\"], [\"NANCY S\\\\.\", \"NANCY S\"], [\"JESSICA E\\\\.\", \"JESSICA E\"],\n",
    "            [\"PATRICIA C\\\\.\", \"PATRICIA C\"], [\"JESSICA P\\\\.\", \"JESSICA P\"], [\"YOLANDA B\\\\.\", \"YOLANDA B\\\\.\"],\n",
    "            [\"LUZ M\\\\.\", \"LUZ M\"], [\"EDGAR\\\\.\", \"EDGAR\"], [\"C\\\\. ARTURO\", \"C ARTURO\"], [\"ALEXANDER A\\\\.\", \"ALEXANDER A\"],\n",
    "            [\"RENE G\\\\.\", \"RENE G\"], [\"GUILLERMO S\\\\.\", \"GUILLERMO S\"], [\"FANNY L\\\\. \",  \"FANNY L\"], [\"ELISA \\\\(LA\", \"ELISA\"],\n",
    "            [\"JULIA \\\\(LA\", \"JULIA\"], [\"ACEVEDO DIEZ CECILIA\", \"ACEVEDO DIEZ CECILIA DEL PILAR\"], [\" J. \", \" J \"],\n",
    "            [\" K. \", \" K \"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05a63ec6",
   "metadata": {},
   "source": [
    "### 2.3. Replacing names with issues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "77f62c47",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Gigabyte\\AppData\\Local\\Temp\\ipykernel_68832\\4277728364.py:2: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  files_reports[\"juez_\"] = files_reports[\"juez_\"].str.replace(name_rep[0], name_rep[1])\n"
     ]
    }
   ],
   "source": [
    "for name_rep in name_reps:\n",
    "    files_reports[\"juez_\"] = files_reports[\"juez_\"].str.replace(name_rep[0], name_rep[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5353a8a",
   "metadata": {},
   "source": [
    "### 2.4. Obtaining the names of judges"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a96cd4a",
   "metadata": {},
   "source": [
    "Some cases have multiple judges assigned to them. As a result, we need to extract these names as we will match the case with the judge information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f57f87f7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "files_reports = files_reports[files_reports[\"juez_\"].notna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7fdbf7b0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "files_reports[\"juez_splitted\"] = files_reports[\"juez_\"].apply(lambda row: row.split(\".\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "12f99917",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "files_reports[\"n_judges_case\"] = files_reports[\"juez_splitted\"].apply(lambda row: len(row))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1e1de66b",
   "metadata": {},
   "outputs": [],
   "source": [
    "judge_names = files_reports[files_reports[\"n_judges_case\"] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "366e60bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "multiple_judge_names = files_reports[files_reports[\"n_judges_case\"] != 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0f6cb645",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Gigabyte\\AppData\\Local\\Temp\\ipykernel_68832\\160945290.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  multiple_judge_names[\"juez_1\"] = multiple_judge_names[\"juez_splitted\"].apply(lambda row: row[0])\n",
      "C:\\Users\\Gigabyte\\AppData\\Local\\Temp\\ipykernel_68832\\160945290.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  multiple_judge_names[\"juez_2\"] = multiple_judge_names[\"juez_splitted\"].apply(lambda row: row[1])\n",
      "C:\\Users\\Gigabyte\\AppData\\Local\\Temp\\ipykernel_68832\\160945290.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  multiple_judge_names[\"juez_3\"] = multiple_judge_names[\"juez_splitted\"].apply(lambda row: row[2])\n"
     ]
    }
   ],
   "source": [
    "multiple_judge_names[\"juez_1\"] = multiple_judge_names[\"juez_splitted\"].apply(lambda row: row[0])\n",
    "multiple_judge_names[\"juez_2\"] = multiple_judge_names[\"juez_splitted\"].apply(lambda row: row[1])\n",
    "multiple_judge_names[\"juez_3\"] = multiple_judge_names[\"juez_splitted\"].apply(lambda row: row[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "63556233",
   "metadata": {},
   "outputs": [],
   "source": [
    "judge_names = judge_names.rename(columns={\"juez_\": \"juez\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8c02897",
   "metadata": {},
   "source": [
    "### 2.5. Fuzzy merge with Lab Experiment Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "201e975b",
   "metadata": {},
   "source": [
    "Creating debuggings dataset to simulate the fuzzy merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "cda37e2d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['expediente_n°_', 'organo_jurisdiccional_', 'distrito_judicial_',\n",
       "       'juez', 'especialista_legal_', 'fecha_de_inicio_', 'proceso_',\n",
       "       'observacion_', 'especialidad_', 'materia_s_', 'estado_',\n",
       "       'etapa_procesal_', 'fecha_conclusion_', 'ubicacion_',\n",
       "       'motivo_conclusion_', 'sumilla_', 'juez_splitted', 'n_judges_case'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "judge_names.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "6a822c2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "debug_judges = judge_names[(judge_names[\"juez\"] == \"CRUZADO MEJIA MARTIN VALDEMAR\") |\n",
    "                           (judge_names[\"juez\"] == \"APAGUEÑO REATEGUI BRYAN ENRIQUE\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "2b22e8af",
   "metadata": {},
   "outputs": [],
   "source": [
    "debug_participants = amag_ii_participants[(amag_ii_participants[\"participant_apellido_nombre\"] == \"CRUZADO MEJIA MARTIN VALDEMAR\") |\n",
    "                                          (amag_ii_participants[\"participant_apellido_nombre\"] == \"APAGUEÑO REATEGUI BRYAN ENRIQUE\")]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d0079db",
   "metadata": {},
   "source": [
    "Fuzzy match of cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "d04e01d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Gigabyte\\AppData\\Local\\Temp\\ipykernel_68832\\3876909639.py:45: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_1['matches'] = m\n",
      "C:\\Users\\Gigabyte\\AppData\\Local\\Temp\\ipykernel_68832\\3876909639.py:48: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_1['matches'] = m2\n"
     ]
    }
   ],
   "source": [
    "matched_judge_name1 = fuzzy_merge(debug_judges, debug_participants, \"juez\", \"participant_apellido_nombre\", threshold=90, limit=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "e684782a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "amag_ii_cases = matched_judge_name1.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c8bc9f7",
   "metadata": {},
   "source": [
    "# 3. Creating CEJ datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "babb94ba",
   "metadata": {},
   "source": [
    "A pending task would be to bind the rows of all the dataframes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45a2f3b3",
   "metadata": {},
   "source": [
    "## Follow up dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ff5ec622",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Gigabyte\\AppData\\Local\\Temp\\ipykernel_68832\\994655769.py:1: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version. Use on_bad_lines in the future.\n",
      "\n",
      "\n",
      "  files_follow_up = pd.read_csv(dc_raw_path + \"/DF_follow_up_cleaner_2022.csv\", error_bad_lines=False)\n",
      "Skipping line 8128: expected 10 fields, saw 11\n",
      "\n"
     ]
    }
   ],
   "source": [
    "files_follow_up = pd.read_csv(dc_raw_path + \"/DF_follow_up_cleaner_2022.csv\", error_bad_lines=False)\n",
    "files_follow_up = clean_names(files_follow_up)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c838a3d",
   "metadata": {},
   "source": [
    "# Procedural parts dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "8419b808",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "files_procedural_parts = pd.read_csv(dc_raw_path + \"/DF_procedural_parts_2022.csv\")\n",
    "files_procedural_parts = clean_names(files_procedural_parts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "e68e6415",
   "metadata": {},
   "outputs": [],
   "source": [
    "files_procedural_parts[\"expediente_n°_\"] = files_procedural_parts[\"expediente_n°_\"].apply(lambda row: row.split(\"\\\\\")[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c946142",
   "metadata": {},
   "source": [
    "## Downloads dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b874163b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "files_downloads = pd.read_csv(dc_raw_path + \"/DF_DOWNLOADS_2022.csv\")\n",
    "files_downloads = clean_names(files_downloads)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38a8a45d",
   "metadata": {},
   "source": [
    "### Merging complementary case data with amag ii cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "f80737ca",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "reportes_amag_ii_raw = pd.merge(amag_ii_cases, files_reports, how=\"inner\", on=\"expediente_n°_\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "cff08574",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "follow_up_amag_ii_raw = pd.merge(amag_ii_cases, files_follow_up, how=\"inner\", on=\"expediente_n°_\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "0f446412",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "procedural_parts_amag_ii_raw = pd.merge(amag_ii_cases, files_procedural_parts, how=\"inner\", on=\"expediente_n°_\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "bb5eb8ba",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "downloads_amag_ii_raw = pd.merge(amag_ii_cases, files_downloads, how=\"inner\", left_on=\"expediente_n°_\", right_on=\"expediente_num\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "b4350e8a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function create_pickle in module __main__:\n",
      "\n",
      "create_pickle(object_name, file_name: str, path: str) -> None\n",
      "    Creates a pickle file for object. Note: Path should have no slash \n",
      "    at the end\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(create_pickle)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac250445",
   "metadata": {},
   "source": [
    "Storing data on `.pkl` files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "a5fc8cf3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "create_pickle(amag_ii_cases, \"amag_ii_cases.pkl\", dc_temp_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "a79cd213",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "create_pickle(reportes_amag_ii_raw, \"reportes_amag_ii_raw.pkl\", dc_temp_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "e33c751d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "create_pickle(follow_up_amag_ii_raw, \"follow_up_amag_ii_raw.pkl\", dc_temp_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "7d8fc991",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "create_pickle(procedural_parts_amag_ii_raw, \"procedural_parts_amag_ii_raw.pkl\", dc_temp_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "b63796dc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "create_pickle(downloads_amag_ii_raw, \"downloads_amag_ii_raw.pkl\", dc_temp_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34856235",
   "metadata": {},
   "source": [
    "# 4. Preprocessing and cleaning of datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb7691d3",
   "metadata": {},
   "source": [
    "Reading gender dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "06ae6265",
   "metadata": {},
   "outputs": [],
   "source": [
    "gender_dataset = pd.read_csv(dc_raw_path + \"/harvard_set_gender.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "4c687787",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:7: DeprecationWarning: invalid escape sequence '\\,'\n",
      "<>:7: DeprecationWarning: invalid escape sequence '\\,'\n",
      "C:\\Users\\Gigabyte\\AppData\\Local\\Temp\\ipykernel_68832\\3245748647.py:7: DeprecationWarning: invalid escape sequence '\\,'\n",
      "  punctuations = '''!()[]{};:'\"\\,<>./¿?@#$%^&*_–~=+¨`“”’|0123456789'''  # all but hyphens\n"
     ]
    }
   ],
   "source": [
    "def spanish_cleaner(txt_file):\n",
    "    text = txt_file\n",
    "    text = re.sub(r\"(&[a-zA-Z]*;)\", \" \", text)  # the txt files had some unwanted text like &rsquo; this line removes such text\n",
    "    text = text.lower()\n",
    "\n",
    "    # remove punctuation and numbers from the string\n",
    "    punctuations = '''!()[]{};:'\"\\,<>./¿?@#$%^&*_–~=+¨`“”’|0123456789'''  # all but hyphens\n",
    "    for x in text.lower(): \n",
    "        if x in punctuations: \n",
    "            text = text.replace(x, \"\")\n",
    "\n",
    "    # replacing encoding characters\n",
    "    enc_characters = [\" st \", \" nd \", \" rd \", \" th \", \"srl\", \"lpfvf\", \"pctc\", \"jmxcff\", \"ayrq\", \"axu\", \"oadk\", \"jcxj\", \"nplt\", \"eef\", \"fcfc\", \"qyoc\", \"gobpe\", \"pfg\", \"vqrx\", \"csjppj\", \"xas\", \"feeback\", \"hafceqc\", \"xqj\", \"hellip\", \"rsquo\", \"ldquo\", \"rdquo\", \"ndash\", \"-\", \"n°\", \"nº\", \"º\", \"°\", \"dprgdonpdl\", \"«\", \"»\", \"…\", \"derjudicialpoderjudicialpoderjudicialpoderjudicialpoderjudicialpoderjudicialpoderjudicialpoderjudicialpoderjudicialpoderjudicialpoderjudicialpoderjudicialpoderjudicialpoderjudicialpoderjudicialpoderjudicialpoderjudicialpoderjudicialpoderjudicialpoderj\", \"ii\", \"iii\", \"vii\", \"viii\"]\n",
    "    \n",
    "    for item in enc_characters:\n",
    "        text = text.replace(item, \" \")\n",
    "    \n",
    "    # cleaning for spanish stop words\n",
    "    stopword_es = nltk.corpus.stopwords.words('spanish') # loading spanish stop words\n",
    "    custom_substrs = [\"http\", \"hangouts\", \"meet\", \"gmailcom\"] # html related\n",
    "    custom_gender_words = [\"él\", \"ella\", \"la\", \"ese\", \"esa\", \"esos\", \"esas\", \"este\", \"esta\", \"aquel\", \"aquella\", \"aquellos\", \"aquellas\", \"lo\", \"la\", \"los\", \"las\", \"aquel\", \"aquella\", \"mío\", \"mía\", \"míos\", \"mías\", \"suyo\", \"suya\", \"suyos\", \"suyas\"] # list with pronouns associated to a specific gender\n",
    "    length_custom_stopwords = len(custom_substrs)\n",
    "    words = text.split() # tokenizing sentence\n",
    "    cleaned_words = [word for word in words if (word not in stopword_es and len(word) > 1) or word in custom_gender_words]\n",
    "     \n",
    "    sentence_no_custom = [] # omitting words that contain \n",
    "    for cleaned_word in cleaned_words:\n",
    "        counter_stopwords = 0\n",
    "        for word in custom_substrs: # evaluating if word contains substr\n",
    "            if word not in cleaned_word: # if passes, +1 for counter\n",
    "                counter_stopwords += 1\n",
    "            if counter_stopwords == length_custom_stopwords: # append if passes all custom substrs tests\n",
    "                sentence_no_custom.append(cleaned_word)\n",
    "\n",
    "    return \" \".join(sentence_no_custom)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "661a6d03",
   "metadata": {},
   "source": [
    "## 4.1. Preprocessing of downloads and follow up "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a49dd12",
   "metadata": {},
   "source": [
    "### Downloads Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "4ac881dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lowercase to text\n",
    "downloads_amag_ii_raw[\"text\"] = downloads_amag_ii_raw[\"text\"].apply(lambda text: text.lower() \n",
    "                                                                    if type(text) is str else text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "dd668a82",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# cleaning the text from the cases\n",
    "downloads_amag_ii_raw[\"text\"] = downloads_amag_ii_raw[\"text\"].apply(lambda text: spanish_cleaner(text) \n",
    "                                                                    if type(text) is str else text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27e8842e",
   "metadata": {},
   "source": [
    "### Downloads Follow Up"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dcfd6b9",
   "metadata": {},
   "source": [
    "Fixing the date of the resolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "59b703dd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:2: DeprecationWarning: invalid escape sequence '\\d'\n",
      "<>:2: DeprecationWarning: invalid escape sequence '\\d'\n",
      "C:\\Users\\Gigabyte\\AppData\\Local\\Temp\\ipykernel_68832\\1630532510.py:2: DeprecationWarning: invalid escape sequence '\\d'\n",
      "  lambda date: datetime.strptime(re.match(\"(\\d+[-/]\\d+[-/]\\d+)\",\n"
     ]
    }
   ],
   "source": [
    "follow_up_amag_ii_raw[\"fecha_de_resolucion_ingreso_\"] = follow_up_amag_ii_raw[\"fecha_de_resolucion_ingreso_\"].apply(\n",
    "                                                        lambda date: datetime.strptime(re.match(\"(\\d+[-/]\\d+[-/]\\d+)\", \n",
    "                                                        date)[0], \"%d/%m/%Y\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dde6b704",
   "metadata": {},
   "source": [
    "Remove extra white space and lower \"acto\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "204f502b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lowercase to text\n",
    "follow_up_amag_ii_raw[\"acto_\"] = follow_up_amag_ii_raw[\"acto_\"].apply(lambda text: text.lower() \n",
    "                                                                    if type(text) is str else text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "4c14ec0e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# cleaning the text from the cases\n",
    "follow_up_amag_ii_raw[\"acto_\"] = follow_up_amag_ii_raw[\"acto_\"].apply(lambda text: spanish_cleaner(text) \n",
    "                                                                    if type(text) is str else text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82d48fb4",
   "metadata": {},
   "source": [
    "Remove extra white space and lower \"sumilla\" (from merged dataframes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "2fea21ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "sumillas = [\"sumilla__x\", \"sumilla__y\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "e8cbcd36",
   "metadata": {},
   "outputs": [],
   "source": [
    "for sumilla in sumillas:\n",
    "    # lowercase to text\n",
    "    follow_up_amag_ii_raw[sumilla] = follow_up_amag_ii_raw[sumilla].apply(lambda text: text.lower() \n",
    "                                                                    if type(text) is str else text)\n",
    "    # cleaning the text from the cases\n",
    "    follow_up_amag_ii_raw[sumilla] = follow_up_amag_ii_raw[sumilla].apply(lambda text: spanish_cleaner(text)\n",
    "                                                                    if type(text) is str else text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38835d03",
   "metadata": {},
   "source": [
    "Remove extra white space and lower \"descripcion de usuario\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "501c67cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lowercase to text\n",
    "follow_up_amag_ii_raw[\"descripcion_de_usuario_\"] = follow_up_amag_ii_raw[\"descripcion_de_usuario_\"].apply(lambda text: text.lower() \n",
    "                                                                    if type(text) is str else text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "981c9056",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# cleaning the text from the cases\n",
    "follow_up_amag_ii_raw[\"descripcion_de_usuario_\"] = follow_up_amag_ii_raw[\"descripcion_de_usuario_\"].apply(lambda text: spanish_cleaner(text) \n",
    "                                                                    if type(text) is str else text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa2286fe",
   "metadata": {},
   "source": [
    "Create variable that identifies rows with pdf or docx file in downloads dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "94537441",
   "metadata": {},
   "outputs": [],
   "source": [
    "follow_up_amag_ii_raw[\"descargado\"] = follow_up_amag_ii_raw[\"descripcion_de_usuario_\"].apply(lambda text: 1\n",
    "                                                                                            if \"descargado\" in text\n",
    "                                                                                            else 0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Judges Outcomes",
   "language": "python",
   "name": "judges_outcomes"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
